@article{locatello2019fairness,
  title={On the Fairness of Disentangled Representations},
  author={Locatello, Francesco and Abbati, Gabriele and Rainforth, Tom and Bauer, Stefan and Sch{\"o}lkopf, Bernhard and Bachem, Olivier},
  journal={arXiv preprint arXiv:1905.13662},
  year={2019},
  url_pdf={https://arxiv.org/pdf/1905.13662.pdf},
  abstract={Recently there has been a significant interest in learning disentangled representations, as they promise increased interpretability, generalization to unseen scenarios and faster learning on downstream tasks. In this paper, we investigate the usefulness of different notions of disentanglement for improving the fairness of downstream prediction tasks based on representations. We consider the setting where the goal is to predict a target variable based on the learned representation of high-dimensional observations (such as images) that depend on both the target variable and an unobserved sensitive variable. We show that in this setting both the optimal and empirical predictions can be unfair, even if the target variable and the sensitive variable are independent. Analyzing more than 12600 trained representations of state-of-the-art disentangled models, we observe that various disentanglement scores are consistently correlated with increased fairness, suggesting that disentanglement may be a useful property to encourage fairness when sensitive variables are not observed.}
}

@article{wenk2019odin,
  title={ODIN: ODE-Informed Regression for Parameter and State Inference in Time-Continuous Dynamical Systems},
  author={Wenk*, Philippe and Abbati*, Gabriele and Bauer, Stefan and Osborne, Michael A and Krause, Andreas and Sch{\"o}lkopf, Bernhard},
  journal={arXiv preprint arXiv:1902.06278},
  year={2019},
  url_pdf={https://arxiv.org/pdf/1902.06278.pdf},
  abstract={Parameter inference in ordinary differential equations is an important problem in many applied sciences and in engineering, especially in a data-scarce setting. In this work, we introduce a novel generative modeling approach based on constrained Gaussian processes and use it to create a computationally and data efficient algorithm for state and parameter inference. In an extensive set of experiments, our approach outperforms its competitors both in terms of accuracy and computational cost for parameter inference. It also shows promising results for the much more challenging problem of model selection.}
}

@article{orozco2018mordred,
  title={MOrdReD: Memory-based Ordinal Regression Deep Neural Networks for Time Series Forecasting},
  author={Orozco, Bernardo P{\'e}rez and Abbati, Gabriele and Roberts, Stephen},
  journal={arXiv preprint arXiv:1803.09704},
  year={2018},
  url_pdf={https://arxiv.org/pdf/1803.09704.pdf},
  abstract={Time series forecasting is ubiquitous in the modern world. Applications range from health care to astronomy, include climate modelling, financial trading and monitoring of critical engineering equipment. To offer value over this range of activities we must have models that not only provide accurate forecasts but that also quantify and adjust their uncertainty over time. Furthermore, such models must allow for multimodal, non-Gaussian behaviour that arises regularly in applied settings. In this work, we propose a novel, end-to-end deep learning method for time series forecasting. Crucially, our model allows the principled assessment of predictive uncertainty as well as providing rich information regarding multiple modes of future data values. Our approach not only provides an excellent predictive forecast, shadowing true future values, but also allows us to infer valuable information, such as the predictive distribution of the occurrence of critical events of interest, accurately and reliably even over long time horizons. We find the method outperforms other state-of-the-art algorithms, such as Gaussian Processes. }
}
